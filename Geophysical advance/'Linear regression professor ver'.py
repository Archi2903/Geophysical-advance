'Linear regression'
'Statistical aspects of leaat squares regression'
'Least squares regression is a method to find the best-fitting line through a set of points in a scatter plot.'

'блок настроек и импорта библиотек'
import numpy as np # для работы с массивами и матрицами
import matplotlib.pyplot as plt # для построения графиков
from sklearn.linear_model import LinearRegression # Используется для построения линейной регрессионной модели
from sklearn.preprocessing import PolynomialFeatures # для полиномиальной регрессии
 
import matplotlib.font_manager as fm # для работы с шрифтами
import matplotlib as mpl # для работы с графиками основной модуль, позволяет задавать глобальные настройки оформления графиков.

# 예: Windows 기본 한글 글꼴 중 하나 설정 (Malgun Gothic)
plt.rcParams['font.family'] = 'Malgun Gothic' #Установка шрифта Malgun Gothic как основного шрифта для всех графиков.
# Обеспечивает корректное отображение корейских символов на графиках (в противном случае могут отображаться квадратики или знаки вопроса).

# 음수 기호 깨짐 방지
mpl.rcParams['axes.unicode_minus'] = False #Устанавливает параметр, который позволяет корректно отображать минус («−») в осях графиках, даже если используется шрифт, который не поддерживает этот символ.
'________________________________________________________________________________________'

'DATA'
# Данные для линейной регрессии
t = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)  # Входные данные, преобразованный в двумерный массив (через reshape)
# В машинном обучении большинство моделей требуют, чтобы входные данные были в виде двумерного массива — даже если есть только один признак.
y = np.array([109.4, 187.5, 267.5, 331.9, 386.1, 428.4, 452.2, 498.1, 512.3, 513.0])

'Создание полиномиальных признаков (второй степени)'
'Полиномы polynomial - необходима,чтобы модель могла описывать нелинейные зависимости между входом и выходом'
poly = PolynomialFeatures(degree=2) 
# Создаётся объект poly класса PolynomialFeatures с параметром degree=2, что означает, что мы хотим создать полиномиальные признаки второй степени.
# например, если у нас есть признак x, то полиномиальные признаки будут x и x^2.
# В результате мы получим два новых признака: x и x^2, которые будут использоваться в модели линейной регрессии.
t_poly = poly.fit_transform(t)
# fit-анализирует структуру данных (хотя тут это формальность) transform-преобразует входные данные t в полиномиальные признаки.
# В результате t_poly будет содержать два столбца: первый столбец - это t, а второй - это t^2.
'Проверка формулы полинома где G=[1, t, -1/2*t^2]'
t_poly_check = t_poly.copy() # Создаём копию t_poly, чтобы не изменять оригинальный массив.
t_poly_check[:, 2] *= -0.5 # Умножаем третий столбец (t^2) на -0.5, чтобы получить формулу G=[1, t, -1/2*t^2].
t_poly_check # Проверяем получившуюся матрицу t_poly_check.
# print (t_poly_check) # Выводим на экран получившуюся матрицу t_poly_check.
"""    [  1. ,   1. ,  -0.5],
       [  1. ,   2. ,  -2. ],
       [  1. ,   3. ,  -4.5],
       [  1. ,   4. ,  -8. ],
       [  1. ,   5. , -12.5],
       [  1. ,   6. , -18. ],
       [  1. ,   7. , -24.5],
       [  1. ,   8. , -32. ],
       [  1. ,   9. , -40.5],
       [  1. ,  10. , -50. ]"""

'Обучение модели регрессии'
# 계수 출력 (-0.5a*t^2 + b*t + c 형태)
a, b, c = model.coef_[2], model.coef_[1], model.intercept_
print(f"회귀식: y = {a:.4f} * t^2 + {b:.4f} * t + {c:.4f}")
print('')

# y(t) = m_1 + m_2 t - (1/2)m_3 t^2
print(f"교재 regression model:")
print(f"y = {c:.4f} + {b:.4f} * t - (1/2) {a/(-0.5):.4f} * t^2")