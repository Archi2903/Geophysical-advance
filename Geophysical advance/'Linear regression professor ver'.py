'Linear regression'
'Statistical aspects of leaat squares regression'
'Least squares regression is a method to find the best-fitting line through a set of points in a scatter plot.'

'–±–ª–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫'
import numpy as np # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∞—Å—Å–∏–≤–∞–º–∏ –∏ –º–∞—Ç—Ä–∏—Ü–∞–º–∏
import matplotlib.pyplot as plt # –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
from sklearn.linear_model import LinearRegression # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
from sklearn.preprocessing import PolynomialFeatures # –¥–ª—è –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
 
import matplotlib.font_manager as fm # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —à—Ä–∏—Ñ—Ç–∞–º–∏
import matplotlib as mpl # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å, –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞–≤–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤.

# Ïòà: Windows Í∏∞Î≥∏ ÌïúÍ∏Ä Í∏ÄÍº¥ Ï§ë ÌïòÎÇò ÏÑ§Ï†ï (Malgun Gothic)
plt.rcParams['font.family'] = 'Malgun Gothic' #–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —à—Ä–∏—Ñ—Ç–∞ Malgun Gothic –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞ –¥–ª—è –≤—Å–µ—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤.
# –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ—Ä–µ–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö (–≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º–æ–≥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –∫–≤–∞–¥—Ä–∞—Ç–∏–∫–∏ –∏–ª–∏ –∑–Ω–∞–∫–∏ –≤–æ–ø—Ä–æ—Å–∞).

# ÏùåÏàò Í∏∞Ìò∏ Íπ®Ïßê Î∞©ÏßÄ
mpl.rcParams['axes.unicode_minus'] = False #–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –º–∏–Ω—É—Å (¬´‚àí¬ª) –≤ –æ—Å—è—Ö –≥—Ä–∞—Ñ–∏–∫–∞—Ö, –¥–∞–∂–µ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —à—Ä–∏—Ñ—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç—Ç–æ—Ç —Å–∏–º–≤–æ–ª.
'________________________________________________________________________________________'

'DATA'
# –î–∞–Ω–Ω—ã–µ –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
t = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)  # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π –≤ –¥–≤—É–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ (—á–µ—Ä–µ–∑ reshape)
# –í –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Ç—Ä–µ–±—É—é—Ç, —á—Ç–æ–±—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –≤ –≤–∏–¥–µ –¥–≤—É–º–µ—Ä–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ ‚Äî –¥–∞–∂–µ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫.
y = np.array([109.4, 187.5, 267.5, 331.9, 386.1, 428.4, 452.2, 498.1, 512.3, 513.0])

'–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Ç–æ—Ä–æ–π —Å—Ç–µ–ø–µ–Ω–∏)'
'–ü–æ–ª–∏–Ω–æ–º—ã polynomial - –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞,—á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –æ–ø–∏—Å—ã–≤–∞—Ç—å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –≤—Ö–æ–¥–æ–º –∏ –≤—ã—Ö–æ–¥–æ–º'
poly = PolynomialFeatures(degree=2) 
# –°–æ–∑–¥–∞—ë—Ç—Å—è –æ–±—ä–µ–∫—Ç poly –∫–ª–∞—Å—Å–∞ PolynomialFeatures —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º degree=2, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º—ã —Ö–æ—Ç–∏–º —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ç–æ—Ä–æ–π —Å—Ç–µ–ø–µ–Ω–∏.
# –Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫ x, —Ç–æ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—É–¥—É—Ç x –∏ x^2.
# –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –º—ã –ø–æ–ª—É—á–∏–º –¥–≤–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞: x –∏ x^2, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –º–æ–¥–µ–ª–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.
t_poly = poly.fit_transform(t)
# fit-–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö (—Ö–æ—Ç—è —Ç—É—Ç —ç—Ç–æ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å) transform-–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ t –≤ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
# –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ t_poly –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞: –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü - —ç—Ç–æ t, –∞ –≤—Ç–æ—Ä–æ–π - —ç—Ç–æ t^2.
'–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º—É–ª—ã –ø–æ–ª–∏–Ω–æ–º–∞ –≥–¥–µ G=[1, t, -1/2*t^2]'
t_poly_check = t_poly.copy() # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é t_poly, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤.
t_poly_check[:, 2] *= -0.5 # –£–º–Ω–æ–∂–∞–µ–º —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü (t^2) –Ω–∞ -0.5, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ñ–æ—Ä–º—É–ª—É G=[1, t, -1/2*t^2].
t_poly_check # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–∞—Ç—Ä–∏—Ü—É t_poly_check.
# print (t_poly_check) # –í—ã–≤–æ–¥–∏–º –Ω–∞ —ç–∫—Ä–∞–Ω –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–∞—Ç—Ä–∏—Ü—É t_poly_check.
"""   [  1. ,   1. ,  -0.5],
       [  1. ,   2. ,  -2. ],
       [  1. ,   3. ,  -4.5],
       [  1. ,   4. ,  -8. ],
       [  1. ,   5. , -12.5],
       [  1. ,   6. , -18. ],
       [  1. ,   7. , -24.5],
       [  1. ,   8. , -32. ],
       [  1. ,   9. , -40.5],
       [  1. ,  10. , -50. ]"""

'–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏'
"""–ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏ –º–∞—Ö –ø—Ä–∞–≤–¥–æ–ø–æ–±–æ–¥–∏—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ Ml2
—Ç–æ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—é—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
# ÌöåÍ∑Ä Î™®Îç∏ ÌïôÏäµ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
#model = LinearRegression() # –°–æ–∑–¥–∞—ë—Ç—Å—è –æ–±—ä–µ–∫—Ç LinearRegression() –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sklearn.linear_model
# y= ax1+bx2+c
#model.fit(t_poly, y) # –ú–µ—Ç–æ–¥ .fit(X, y) –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö

# Í≥ÑÏàò Ï∂úÎ†• (-0.5a*t^2 + b*t + c ÌòïÌÉú) –í—ã–≤–æ–¥ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–µ –£—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: y = a * t¬≤ + b * t + c
#m1, m2, m3 = model.coef_[2], model.coef_[1], model.intercept_ #–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏
# model.coef_ ‚Äî –º–∞—Å—Å–∏–≤ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
# coef_[2] = m1 ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏ t^2
# coef_[1] = m2 ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏ t
# model.intercept_ ‚Äî —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω (—Å–≤—è–∑–∞–Ω —Å c)
# intercept_ = m3 ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (—Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω)
#print(f"ÌöåÍ∑ÄÏãù: y = {m1:.4f} * t^2 + {m2:.4f} * t + {m3:.4f}") # –ü–µ—Ä–≤–∞—è —Ñ–æ—Ä–º–∞ –≤—ã–≤–æ–¥–∞ —É—Ä–∞–≤–Ω–µ–Ω–∏—è
# .4f –æ–∑–Ω–∞—á–∞–µ—Ç –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ 4-—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π.
#print('')
# –í—ã–≤–æ–¥–∏—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É ‚Äî –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –±–ª–æ–∫–æ–≤

# y(t) = m_1 + m_2 t - (1/2)m_3 t^2
#print(f"ÍµêÏû¨ regression model:") # –û–ø–∏—Å–∞–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π —Ñ–æ—Ä–º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏—è ‚Äî –∏–∑ —É—á–µ–±–Ω–∏–∫–∞ (ÍµêÏû¨).
#print(f"y = {m3:.4f} + {m2:.4f} * t - (1/2) {m1/(-0.5):.4f} * t^2")
"______________________________________________________________________________________"
"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ Regression"
"""# ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞
t_fit = np.linspace(1, 10, 100).reshape(-1, 1)
# –°–æ–∑–¥–∞—ë—Ç—Å—è 100 —Ç–æ—á–µ–∫ t –æ—Ç 1 –¥–æ 10 (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ), —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö
t_fit_poly = poly.transform(t_fit)
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º t_fit –≤ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–º–æ—â—å—é —Ä–∞–Ω–µ–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ poly, –Ω–∞–ø—Ä–∏–º–µ—Ä t->[t^2,t]
y_fit = model.predict(t_fit_poly)
# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è y –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —ç—Ç–∏—Ö –Ω–æ–≤—ã—Ö t-–∑–Ω–∞—á–µ–Ω–∏–π.y=m1t^2+m2t+c
# ÏãúÍ∞ÅÌôî
plt.figure(figsize=(5, 3))  # (Í∞ÄÎ°ú, ÏÑ∏Î°ú) Îã®ÏúÑÎäî Ïù∏Ïπò
plt.scatter(t, y, color='blue', s=10, marker='x', label='Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞')
plt.plot(t_fit, y_fit, color='red', lw=0.5, label='2Ï∞® ÌöåÍ∑Ä Í≥°ÏÑ†')
plt.xlabel('t (s)')
plt.ylabel('y (m)')
plt.title('2Ï∞® Îã§Ìï≠ ÌöåÍ∑Ä (Quadratic Regression)')
plt.legend()
plt.grid(True)
plt.show()"""
"____________________________________________________"

"Example 2.2"
"""Goal: –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –≤–∏–¥–∞ y(t)=m1+m2t-0.5m3^2
–∏ –æ—Ü–µ–Ω–∏—Ç—å –¥–æ–≤–µ—Ä–∏–µ –∫ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É"""

# 1. Îç∞Ïù¥ÌÑ∞ Ï†ïÏùò
t = np.array([1,2,3,4,5,6,7,8,9,10]).reshape(-1,1)
y = np.array([109.4, 187.5, 267.5, 331.9, 386.1, 428.4, 452.2, 498.1, 512.3, 513.0])

# 2. ÎîîÏûêÏù∏ ÌñâÎ†¨ Íµ¨ÏÑ±: [1, t, -0.5 * t^2] –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –≤–∏–¥–∞ G=[1,t,-0.5t^2]
G = np.hstack([       # –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è (horizontal stack) –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –º–∞—Å—Å–∏–≤–æ–≤ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–∞—Å—Å–∏–≤—ã –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
    np.ones_like(t),  # c (Ï†àÌé∏) —Å–≤–æ–±–æ–¥–Ω—ã–π –°–æ–∑–¥–∞—ë—Ç –º–∞—Å—Å–∏–≤ —Ç–æ–π –∂–µ —Ñ–æ—Ä–º—ã, —á—Ç–æ –∏ t, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –µ–¥–∏–Ω–∏—Ü–∞–º–∏
    t,                # b Í≥ÑÏàò   –ª–∏–Ω–µ–π–Ω—ã–π
    -0.5 * t**2       # a Í≥ÑÏàòÏôÄ Í≥±Ìï¥Ïßà Ìï≠ —Å —É—á–µ—Ç–æ–º T^2 –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π —Ñ–æ—Ä–º—É–ª—ã
])

# 3. ÏÑ†Ìòï ÌöåÍ∑Ä Î™®Îç∏ (Ï†àÌé∏ ÏßÅÏ†ë ÎÑ£ÏóàÏúºÎØÄÎ°ú fit_intercept=False)
# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Å–µ–ø—Ç–∞
model = LinearRegression(fit_intercept=False)
model.fit(G, y)
m_L2 = model.coef_

# 4. ÏïåÎ†§ÏßÑ Ïò§Ï∞® ÌëúÏ§ÄÌé∏Ï∞® –ò–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö
sigma = 8
sigma_squared = sigma ** 2

# 5. Í≥µÎ∂ÑÏÇ∞ ÌñâÎ†¨ Í≥ÑÏÇ∞ –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
GtG_inv = np.linalg.inv(G.T @ G) # –§–æ—Ä–º—É–ª–∞ Cov[mL2]=(sigma^2)(G^T*G)^-1
cov_m_L2 = sigma_squared * GtG_inv

# 6. Í≤∞Í≥º Ï∂úÎ†•
print("Ï∂îÏ†ïÎêú ÌöåÍ∑Ä Í≥ÑÏàò [m3, m2, m1]:", m_L2)
print("\nÏò§Ï∞® Î∂ÑÏÇ∞ œÉ¬≤ =", sigma_squared)
print("\nÍ≥ÑÏàò Í≥µÎ∂ÑÏÇ∞ ÌñâÎ†¨ (Cov[m_L2]):\n", cov_m_L2)
""" Result
[m3, m2, m1]: [16.40833333 96.97128788  9.40833333]

Ïò§Ï∞® Î∂ÑÏÇ∞ œÉ¬≤ = 64

Í≥ÑÏàò Í≥µÎ∂ÑÏÇ∞ ÌñâÎ†¨ (Cov[m_L2]):
 [[ 88.53333333 -33.6         -5.33333333]
 [-33.6         15.44242424   2.66666667]
 [ -5.33333333   2.66666667   0.48484848]]
"""
"_________________________________________________________________________"
"""Goal: –ü–æ—Å—á–∏—Ç–∞—Ç—å 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
m1,m2,m3 –∏—Å–ø–æ–ª—å–∑—É—è
- –û—Ü–µ–Ω–∫—É –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ mL2
- –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É(cov[mL2])
- –ö–≤–∞–Ω—Ç–∏–ª—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (z = 1.96)
"""
from scipy.stats import norm

# z Í∞í (Ï†ïÍ∑úÎ∂ÑÌè¨ Í∏∞Ï§Ä 95% Ïã†Î¢∞ÏàòÏ§Ä) 
#  –ò–º–ø–æ—Ä—Ç –∫–≤–∞–Ω—Ç–∏–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
z = norm.ppf(0.975)  # ÏïΩ 1.96
# ppf = percent point function (–æ–±—Ä–∞—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫ cdf)
# ùëß ‚âà 1.96 z‚âà1.96 –¥–ª—è 95% –¥–æ–≤–µ—Ä–∏—è (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–µ–≥–æ)

# Ïã†Î¢∞Íµ¨Í∞Ñ Í≥ÑÏÇ∞ –†–∞—Å—á—ë—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:
# –§–æ—Ä–º—É–ª–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞: Coef Int = m+-z*se
conf_intervals = []
for i in range(len(m_L2)):
    se = np.sqrt(cov_m_L2[i, i])  # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏
    lower = m_L2[i] - z * se      # –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
    upper = m_L2[i] + z * se      # –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
    conf_intervals.append((lower, upper))

# Í≤∞Í≥º Ï∂úÎ†•
labels = ['m_1', 'm_2', 'm_3']  # –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ m1,m2,m3
for i, (ci, est) in enumerate(zip(conf_intervals, m_L2)):
    print(f"{labels[i]} = {est:.4f},  95% Ïã†Î¢∞Íµ¨Í∞Ñ: ({ci[0]:.4f}, {ci[1]:.4f})")
    """
    m_1 = 16.4083,  95% Ïã†Î¢∞Íµ¨Í∞Ñ: (-2.0334, 34.8501)
    m_2 = 96.9713,  95% Ïã†Î¢∞Íµ¨Í∞Ñ: (89.2692, 104.6733)
    m_3 = 9.4083,  95% Ïã†Î¢∞Íµ¨Í∞Ñ: (8.0436, 10.7731)
    """

"""Goal: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –æ–±—ä—è—Å–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ,
–ø—Ä–∏ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –æ—à–∏–±–æ–∫ ùúé^2, –∏—Å–ø–æ–ª—å–∑—É—è:
- –•–∏-–∫–≤–∞–¥—Ä–∞—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: œá¬≤ = 
- —Å—Ä–∞–≤–Ω–∏—Ç—å –µ—ë —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º œá¬≤ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Å—Ç–µ–ø–µ–Ω—è–º–∏ —Å–≤–æ–±–æ–¥—ã (df)
œá¬≤ (chi_squared) - –Ω–∞—Å–∫–æ–ª—å–∫–æ –±–æ–ª—å—à–∞—è –æ—à–∏–±–∫–∞
df (—Å—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±.)	10 - —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
p-value	–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–≤–∏–¥–µ—Ç—å —Ç–∞–∫—É—é –æ—à–∏–±–∫—É —Å–ª—É—á–∞–π–Ω–æ
"""    
from scipy.stats import chi2 # –ü–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç:œá¬≤

# ÏòàÏ∏° Î∞è ÏûîÏ∞® –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ—Å—Ç–∞—Ç–∫–∏
y_pred = model.predict(G) # y_pred: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
residuals = y - y_pred    # residuals: –æ—Å—Ç–∞—Ç–∫–∏ (—Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏)

# Ïπ¥Ïù¥Ï†úÍ≥± ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞: RSS / sigma^2 –í—ã–±–æ—Ä –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –∏ —Ä–∞—Å—á—ë—Ç RSS(—Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫)
sigma = 8
RSS = np.sum(residuals**2)
chi_squared = RSS / (sigma**2)

# ÏûêÏú†ÎèÑ –°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã v=m-n
df = len(y) - G.shape[1]  # 10 - 3 = 7

# p-value Í≥ÑÏÇ∞ (Ïö∞Ï∏° ÎàÑÏ†Å ÌôïÎ•†) –†–∞—Å—á—ë—Ç p-value
p_value = 1 - chi2.cdf(chi_squared, df=df)
# chi_squared-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–∞—Ç—å –º–µ–Ω—å—à–µ–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
# 1 - cdf ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–∞—Ç—å –±–æ–ª—å—à–µ ‚Üí —Ç–æ –µ—Å—Ç—å –Ω–∞—à–∞ p-value
# –ï—Å–ª–∏ p-value < 0.05  p-value  0.05 ‚Üí –º–æ–¥–µ–ª—å –Ω–µ –æ–±—ä—è—Å–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ö–æ—Ä–æ—à–æ (–≥–∏–ø–æ—Ç–µ–∑–∞ –æ–± –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è)

# Ï∂úÎ†•  –í—ã–≤–æ–¥
print(f"Chi-squared statistic: {chi_squared:.4f}")
print(f"Degrees of freedom: {df}")
print(f"p-value: {p_value:.4e}")
"–ï—Å–ª–∏ p-value < 0.05  p-value  0.05 ‚Üí –º–æ–¥–µ–ª—å –Ω–µ –æ–±—ä—è—Å–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ö–æ—Ä–æ—à–æ (–≥–∏–ø–æ—Ç–µ–∑–∞ –æ–± –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è)"
"""
œá¬≤: 4.1810
Degrees of freedom(df): 7
p-value: 7.5871e-01    
"""
"_________________________________________________________________________"
"Example 2.2: Confidence ellipsoid"
